<Project Sdk="Microsoft.NET.Sdk.Web">

    <PropertyGroup>
        <TargetFramework>net8.0</TargetFramework>
        <Nullable>enable</Nullable>
        <ImplicitUsings>enable</ImplicitUsings>
        <DockerDefaultTargetOS>Linux</DockerDefaultTargetOS>
    </PropertyGroup>

    <ItemGroup>
        <PackageReference Include="LLamaSharp.Backend.Cuda12" Version="0.11.2" />
        <PackageReference Include="Microsoft.AspNetCore.OpenApi" Version="8.0.3"/>
        <PackageReference Include="Microsoft.ML.OnnxRuntime.Gpu" Version="1.17.3" />
        <PackageReference Include="Microsoft.SemanticKernel" Version="1.10.0" />
        <PackageReference Include="Microsoft.SemanticKernel.PromptTemplates.Handlebars" Version="1.10.0" />
        <PackageReference Include="Microsoft.SemanticKernel.Yaml" Version="1.10.0" />
        <PackageReference Include="OllamaSharp" Version="1.1.1" />
        <PackageReference Include="OnnxStack.StableDiffusion" Version="0.31.0" />
        <PackageReference Include="Serilog.AspNetCore" Version="8.0.1" />
        <PackageReference Include="Swashbuckle.AspNetCore" Version="6.4.0"/>
    </ItemGroup>

    <ItemGroup>
      <Content Include="..\.dockerignore">
        <Link>.dockerignore</Link>
      </Content>
    </ItemGroup>

    <ItemGroup>
      <Folder Include="Plugins\" />
      <Folder Include="wwwroot\" />
    </ItemGroup>
    
    <ItemGroup>
        <EmbeddedResource Include="Prompts\**\*.yaml" />
    </ItemGroup>
    
    <ItemGroup>
      <ProjectReference Include="..\..\..\tools\LLamaSharp\LLama.SemanticKernel\LLamaSharp.SemanticKernel.csproj" />
      <ProjectReference Include="..\..\..\tools\LLamaSharp\LLama\LLamaSharp.csproj" />
    </ItemGroup>

</Project>
